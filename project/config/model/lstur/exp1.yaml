# LSTUR

# INFO
name: lstur

#
# DATA
#
# behavior
train_behavior: "data/train/train_behavior.tsv"
val_behavior: "data/train/val_behavior.tsv"
test_behavior: "data/test/test_behavior.tsv"
# news
train_news: "data/train/parsed_news.tsv"
test_news: "data/test/parsed_news.tsv"
# idx maps 
user2int: "data/train/user2int.tsv"
word2int: "data/test/word2int.tsv"
category2int: "data/train/category2int.tsv"
# word embedding weights --> here use the embedding_weights 
# resulting after the test news processing
# so link to <test_dir>/embedding_weights.csv
embedding_weights: "data/test/embedding_weights.csv"

max_history: 50  # Number of sampled click history for each user
num_words_title: 20
num_words_abstract: 50
num_categories: 275 
num_users: 48221 


# MODEL
learning_rate: 0.0001
dropout_probability: 0.2
word_embedding_dim: 300
# Modify the following only if you use another dataset
# entity_embedding_dim:  100
# For additive attention
query_vector_dim: 200
# For CNN
num_filters: 300
window_size: 3
long_short_term_method: "ini"  # initializing lstm with user embedding
#long_short_term_method: "con" # concateneting lstm output with user embedding
# See paper for more detail
masking_probability: 0.5
freeze_word_embeddings: False


# TRAINING
# Checkpoint
checkpoint:
  dirpath: "logs/lightning_logs/checkpoints/lstur_simple_/exp1"
  filename: "{epoch}-{val_auc_epoch:.4f}"
  save_top_k: 3
  verbose: True
  monitor: "val_auc_epoch"
  mode: "max"
  save_last: True

#Logging
logger:
  save_dir: "logs/lightning_logs/tensorboard"
  name: "lstur_simple_"
  version: "exp1"

#EarlyStop
early_stop:
  monitor: 'val_auc_epoch'
  min_delta: 0.0001
  patience: 5
  strict: False
  verbose: True
  mode: 'max'

# DataLoader
train_dataloader:
  num_workers: 8
  batch_size: 256
  shuffle: True
  drop_last: True
val_dataloader:
  num_workers: 16
  batch_size: 1 # must be one by design TODO make it better :)
  shuffle: False
  drop_last: False
test_dataloader:
  num_workers: 16
  batch_size: 1 # must be one by design TODO make it better :)
  shuffle: False
  drop_last: False

# Trainer
trainer:
  max_epochs: 100
  gpus: -1
  accelerator: "ddp"
  weights_summary: "top"
  fast_dev_run: False
#DDPPlugin
find_unused_parameters: False