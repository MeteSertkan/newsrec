# SENTIREC lambda 0.4 m 10

# INFO
name: sentirec

#
# DATA
#
# behavior
train_behavior: "data/ecir2022/train/train_behavior.tsv"
val_behavior: "data/ecir2022/train/val_behavior.tsv"
test_behavior: "data/ecir2022/test/test_behavior.tsv"
# news
train_news: "data/ecir2022/train/parsed_news.tsv"
test_news: "data/ecir2022/test/parsed_news.tsv"
# idx maps 
user2int: "data/ecir2022/train/user2int.tsv"
word2int: "data/ecir2022/test/word2int.tsv"
category2int: "data/ecir2022/_rain/category2int.tsv"
# word embedding weights --> here use the embedding_weights 
# resulting after the test news processing
# so link to <test_dir>/embedding_weights.csv
embedding_weights: "data/ecir2022/test/embedding_weights.csv"

max_history: 50  # Number of sampled click history for each user
num_words_title: 20
num_words_abstract: 50


#MODEL 
learning_rate: 0.0001
dropout_probability: 0.2
# For additive attention
query_vector_dim: 200
# For SelfAttention
num_attention_heads: 15
word_embedding_dim: 300
freeze_word_embeddings: False
# SENTIMENT
sentiment_regularization: True
# Sentiment Classifier 'vader_sentiment' | 'bert_sentiment'
sentiment_classifier: 'vader_sentiment'
# sentiment prediction task  loss coeff , i.e., lambda 
sentiment_prediction_loss_coeff: 0.4
# sentiment regularization task loss coeff, i.e., mu
sentiment_diversity_loss_coeff: 10



# TRAINING
# Checkpoint
checkpoint:
  dirpath: "logs/lightning_logs/checkpoints/sentirec/vader_lambda0p4_mu10"
  filename: "{epoch}-{val_auc_epoch:.4f}"
  save_top_k: 3
  verbose: True
  monitor: "val_auc_epoch"
  mode: "max"
  save_last: True

#Logging
logger:
  save_dir: "logs/lightning_logs/tensorboard"
  name: "sentirec"
  version: "vader_lambda0p4_mu10"

#EarlyStop
early_stop:
  monitor: 'val_auc_epoch'
  min_delta: 0.0001
  patience: 5
  strict: False
  verbose: True
  mode: 'max'

# DataLoader
train_dataloader:
  num_workers: 8
  batch_size: 64
  shuffle: True
  drop_last: True
val_dataloader:
  num_workers: 16
  batch_size: 1 # must be one by design TODO make it better :)
  shuffle: False
  drop_last: False
test_dataloader:
  num_workers: 16
  batch_size: 1 # must be one by design TODO make it better :)
  shuffle: False
  drop_last: False

# Trainer
trainer:
  max_epochs: 100
  gpus: -1
  accelerator: "ddp"
  weights_summary: "top"
  fast_dev_run: False
#DDPPlugin
find_unused_parameters: False