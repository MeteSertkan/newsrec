# SENTIREC - lambda=0.2 - mu=2 distillbert_sst2_sentiment

# INFO
name: sentirec


# DATA
# source
train_dir: "/mnt/nvme-local/msertkan/newsrec/data/recsys2021/mind/train"
test_dir: "/mnt/nvme-local/msertkan/newsrec/data/recsys2021/mind/test"

# Modify the following by the output of `src/dataprocess.py`
num_words: 70972  # 1 + 70971
num_categories: 296  # 1 + 295
num_entities: 12958  # 1 + 12957
num_users: 50001 #  1 + 50000

num_clicked_news_a_user: 50  # Number of sampled click history for each user
num_words_title: 20
num_words_abstract: 50

# determine which attributes to use form dataset
dataset_attributes:
  news: [title, vader_sentiment, distillbert_sst2_sentiment]
  record: []


#MODEL 
learning_rate: 0.0001
dropout_probability: 0.2
# For additive attention
query_vector_dim: 200
# For SelfAttention
num_attention_heads: 15
word_embedding_dim: 300
freeze_word_embeddings: True
# SENTIMENT
sentiment_regularization: True
# Sentiment Classifier 'vader_sentiment' | 'distillbert_sst2_sentiment'
sentiment_classifier: 'distillbert_sst2_sentiment'
# sentiment prediction task  loss coeff , i.e., lambda 
sentiment_prediction_loss_coeff: 0.2
# sentiment regularization task loss coeff, i.e., mu
sentiment_diversity_loss_coeff: 2


# TRAINING

# Checkpoint
checkpoint:
  dirpath: "/mnt/nvme-local/msertkan/newsrec/lightning_logs/checkpoints/sentirec/bert_lambda0p2_mu2"
  filename: "{epoch}-{val_auc_epoch:.4f}"
  save_top_k: 3
  verbose: True
  monitor: "val_auc_epoch"
  mode: "max"
  save_last: True

#Logging
logger:
  save_dir: "/mnt/nvme-local/msertkan/newsrec/lightning_logs/tensorboard"
  name: "sentirec"
  version: "bert_lambda0p2_mu2"

#EarlyStop
early_stop:
  monitor: 'val_auc_epoch'
  min_delta: 0.0001
  patience: 3
  strict: False
  verbose: True
  mode: 'max'

# train / val split , e.g., 0.9 for 90%/10%
train_val_split: 0.9
# DataLoader
train_dataloader:
  num_workers: 8
  batch_size: 64
  shuffle: True
  drop_last: True
val_dataloader:
  num_workers: 24
  batch_size: 1 # must be one by design TODO make it better :)
  shuffle: False
  drop_last: False
test_dataloader:
  num_workers: 24
  batch_size: 1 # must be one by design TODO make it better :)
  shuffle: False
  drop_last: False

# Trainer
trainer:
  max_epochs: 100
  gpus: -1
  accelerator: "ddp"
  weights_summary: "top"
  fast_dev_run: False
  